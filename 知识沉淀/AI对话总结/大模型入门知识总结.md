# 大模型（LLM）入门知识总结

> 本文档是一份从零开始理解大语言模型的学习笔记，基于 MiniMind 项目的学习整理。
> 适合对深度学习和LLM感兴趣的初学者阅读。

---

## 目录

1. [核心概念区分](#一核心概念区分)
2. [常用工具和框架](#二常用工具和框架)
3. [数据相关](#三数据相关)
4. [模型结构](#四模型结构transformer-组件)
5. [训练原理](#五训练原理)
6. [训练参数详解](#六训练参数详解)
7. [强化学习与对齐](#七强化学习与对齐)
8. [常见误区澄清](#八常见误区澄清)
9. [实际应用场景](#九实际应用场景)

---

## 一、核心概念区分

### 1.1 架构、库、数据、权重的关系

| 概念 | 是什么 | 比喻 | 例子 |
|-----|-------|------|------|
| **架构** | 模型的结构设计（设计图纸） | 房子的设计蓝图 | Transformer、Llama架构 |
| **库/框架** | 实现架构的工具 | 建筑工具 | PyTorch、Transformers |
| **数据** | 训练用的文本内容 | 建筑材料 | 网页、书籍、对话 |
| **权重** | 训练后的参数数值 | 建好的房子 | `.pth`、`.safetensors` 文件 |

**关键理解**：
- 架构是"设计理念"，不是代码也不是数据
- 权重只是数字，必须配合架构代码才能使用
- 推理时需要：架构代码 + 权重
- 训练时需要：架构代码 + 数据 → 产生权重

### 1.2 参数与模型大小

**参数**：神经网络中的数字，存储在矩阵里，是模型"学到的知识"的载体。

**模型大小计算**：
```
参数量 × 每个参数的字节数 = 文件大小

7B 参数 × 2字节(float16) = 14GB
26M 参数 × 2字节 = 52MB
```

**单位换算**：
- M = Million = 百万 = 10⁶
- B = Billion = 十亿 = 10⁹
- 7B = 70亿参数

---

## 二、常用工具和框架

| 名称 | 类型 | 作用 | 适用场景 |
|-----|------|------|---------|
| **PyTorch** | 深度学习框架 | 提供张量计算、自动微分、GPU加速 | 训练和研究 |
| **Transformers** | Python库 | Hugging Face的模型库，统一API | 加载模型、训练、推理 |
| **llama.cpp** | C++程序 | 纯CPU推理，轻量高效 | 边缘设备、无GPU环境 |
| **vLLM** | 推理引擎 | GPU高性能推理，高吞吐 | 生产环境部署 |
| **Ollama** | 应用程序 | 一键本地运行大模型 | 个人体验、快速测试 |

---

## 三、数据相关

### 3.1 数据来源

| 来源 | 例子 | 获取方式 |
|-----|------|---------|
| 网络爬取 | 维基百科、新闻、论坛 | 程序自动爬取 |
| 公开数据集 | Common Crawl、The Pile | 直接下载 |
| 书籍/论文 | 电子书、学术文献 | 扫描/电子版 |
| 人工标注 | 问答对、对话 | 雇人写/标注 |
| 大模型生成 | GPT/Qwen生成的对话 | API调用（蒸馏） |

### 3.2 数据清洗

把"脏"数据变"干净"：

| 操作 | 作用 |
|-----|------|
| 去重 | 删除重复的句子/段落 |
| 去噪 | 删除乱码、HTML标签、特殊符号 |
| 过滤 | 删除广告、敏感内容、低质量内容 |
| 格式化 | 统一标点、空格、换行 |
| 长度筛选 | 只保留合适长度的文本 |

### 3.3 数据质量衡量

| 维度 | 好的数据 | 差的数据 |
|-----|---------|---------|
| 准确性 | 事实正确 | 包含错误信息 |
| 完整性 | 句子完整、逻辑通顺 | 截断、乱码 |
| 多样性 | 覆盖多种话题 | 内容单一重复 |
| 无害性 | 没有有害内容 | 包含暴力、歧视 |

### 3.4 数据配比

不同类型数据的比例，决定模型的能力方向：

```
通用模型: 网页60% + 书籍15% + 代码10% + 对话15%
医学模型: 医学文献40% + 医学问答30% + 通用文本30%
代码模型: 代码70% + 通用文本30%
```

---

## 四、模型结构（Transformer 组件）

### 4.1 注意力机制 (Attention)

**作用**：让模型知道"该关注哪些词"

```
句子："我 爱 吃 苹果"
处理"吃"时，重点关注"苹果"（吃的对象）
注意力机制自动学习这种关注关系
```

### 4.2 FFN (前馈网络)

**作用**：对每个位置的信息独立处理

```
注意力层：词之间交流信息（"你看看我，我看看你"）
FFN层：每个词独立处理（"自己消化吸收"）
```

### 4.3 位置编码 (Positional Encoding)

**问题**：注意力机制不知道词的顺序
**解决**：给每个位置加一个"位置标记"

```
"我爱你" vs "你爱我" → 加位置编码后，模型能区分
```

常用方法：RoPE（旋转位置编码）

### 4.4 MoE (混合专家)

**核心思想**：多个"专家"网络，每次只激活部分

```
传统模型：一个大FFN，所有参数都参与计算
MoE模型：多个小FFN（专家），路由器选择2个使用
```

**优势**：参数量大但计算量小（性价比高）

**路由**：决定"这个输入交给哪个专家处理"

### 4.5 一个 Transformer 层

```
输入 → [注意力层] → [残差连接] → [LayerNorm] → [FFN] → [残差连接] → [LayerNorm] → 输出
```

---

## 五、训练原理

### 5.1 训练的本质

**一句话**：让模型不断"猜下一个词"，猜错就调参数，重复几亿次直到猜准。

```
输入："今天天气"
模型预测下一个词 → 应该是"真"
如果猜错 → 调整参数
重复几十亿次 → 模型学会了语言规律
```

### 5.2 训练三步曲

| 步骤 | 名称 | 作用 | 代码 |
|-----|------|------|------|
| 1 | 前向传播 | 数据流过模型，得到预测 | `output = model(input)` |
| 2 | 反向传播 | 计算每个参数的梯度 | `loss.backward()` |
| 3 | 梯度下降 | 用梯度更新参数 | `optimizer.step()` |

### 5.3 损失函数

**作用**：衡量"预测和正确答案差多远"

```
交叉熵损失 = -log(预测正确答案的概率)

预测概率90% → 损失0.1（猜得准）
预测概率10% → 损失2.3（猜得差）
```

### 5.4 梯度

**定义**：告诉参数"往哪个方向调，损失会变小"

**计算方式**：自动微分 + 链式法则（不是一个个试）

```
前向传播时：记录计算图（谁依赖谁）
反向传播时：用链式法则一次算出所有梯度
```

### 5.5 梯度下降

**公式**：`参数_new = 参数_old - 学习率 × 梯度`

**比喻**：站在山上找下山最快的方向，每次走一小步

### 5.6 为什么能这么快？

| 技术 | 作用 |
|-----|------|
| GPU并行 | 几千个核同时计算 |
| 批量处理 | 32条数据一起算，只更新一次参数 |
| 混合精度 | 用16位浮点数，速度翻倍 |
| Flash Attention | 优化注意力计算 |

### 5.7 梯度消失

**问题**：梯度在深层网络中越传越小，导致浅层学不到东西

**解决方案**：
- 残差连接（梯度可以跳过某些层）
- LayerNorm/RMSNorm（稳定数值范围）
- 合适的激活函数（ReLU、SiLU）

---

## 六、训练参数详解

### 6.1 学习率 (Learning Rate)

每次参数更新的步长。

| 学习率 | 效果 |
|-------|------|
| 太大 (0.1) | 不稳定，可能发散 |
| 合适 (0.001) | 平衡速度和精度 |
| 太小 (0.00001) | 收敛太慢 |

通常会用**学习率调度**：开始大，逐渐变小。

### 6.2 Batch Size（批次大小）

一次训练用多少条数据。

| Batch Size | 优点 | 缺点 |
|-----------|------|------|
| 小 (8-16) | 显存少 | 梯度噪声大 |
| 中 (32-64) | 平衡 | 平衡 |
| 大 (128+) | 梯度准确 | 显存占用大 |

### 6.3 层数 (num_hidden_layers)

Transformer 堆叠多少层。

| 层数 | 模型级别 |
|-----|---------|
| 8层 | MiniMind-Small (26M) |
| 16层 | MiniMind (104M) |
| 32层 | 7B级别 |
| 80层 | 70B级别 |

层数越多能力越强，但有收益递减。

### 6.4 维度 (hidden_size)

每层处理的向量有多少个数字。

```
参数量 ≈ 12 × 层数 × 维度²
```

| 维度 | 模型级别 |
|-----|---------|
| 512 | MiniMind-Small |
| 768 | MiniMind |
| 4096 | Llama-7B |

### 6.5 训练轮数 (Epochs)

整个数据集被遍历多少遍。

| 轮数 | 效果 |
|-----|------|
| 1轮 | 可能欠拟合 |
| 2-3轮 | 通常最佳 |
| 5+轮 | 可能过拟合 |

### 6.6 优化器

决定"怎么用梯度更新参数"。

| 优化器 | 特点 |
|-------|------|
| SGD | 简单，收敛慢 |
| Adam | 自适应学习率，收敛快 |
| **AdamW** | Adam + 权重衰减，LLM首选 |

---

## 七、强化学习与对齐

### 7.1 为什么需要强化学习？

预训练+SFT后的模型可能：
- 回答冷冰冰
- 有时候胡说八道
- 不知道拒绝有害问题

需要进一步"对齐"人类偏好。

### 7.2 RLHF / DPO / GRPO

| 算法 | 全称 | 核心思想 |
|-----|------|---------|
| **RLHF** | 人类反馈强化学习 | 训练奖励模型，再用它指导LLM训练 |
| **DPO** | 直接偏好优化 | 直接用偏好数据训练，不需要奖励模型 |
| **GRPO** | 组相对策略优化 | 同一问题生成多个回答，组内比较 |

### 7.3 对齐 (Alignment)

让模型行为符合人类期望：**Helpful（有帮助）、Harmless（无害）、Honest（诚实）**

---

## 八、常见误区澄清

### 误区1：数据量决定模型大小

❌ **错误**：数据多 → 模型大

✅ **正确**：模型大小由架构设计（层数、维度）决定，训练前就定好了

```
同一个7B模型：
- 用1GB数据训练 → 14GB文件，效果差
- 用1TB数据训练 → 14GB文件，效果好
文件大小一样，知识量不同
```

### 误区2：大模型代码很复杂

❌ **错误**：大模型代码量很大

✅ **正确**：核心代码很简洁，复杂度在数学原理和调参经验

```python
# 几乎所有模型的训练循环
for batch in dataloader:
    output = model(batch)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()
```

### 误区3：层数越多越好

❌ **错误**：无限加层就能无限提升

✅ **正确**：有收益递减，需要和参数量、数据量匹配

---

## 九、实际应用场景

### 9.1 大模型的创新维度

| 维度 | 创新内容 |
|-----|---------|
| 架构创新 | 注意力改进、位置编码、MoE |
| 数据创新 | 数据来源、清洗、配比 |
| 训练策略 | 学习率调度、强化学习 |
| 工程创新 | 分布式训练、显存优化 |

### 9.2 私有化/垂直领域模型

```
基础模型（Llama/Qwen）
    ↓
+ 公司/领域数据（产品文档、客服记录、专业知识）
    ↓
微调训练（LoRA/全参数）
    ↓
领域专属模型
```

| 场景 | 数据 | 效果 |
|-----|------|------|
| 医院 | 病历、医学指南 | AI辅助诊断 |
| 律所 | 法律条文、判例 | AI法律助手 |
| 电商 | 商品信息、客服对话 | AI客服 |

### 9.3 数据少怎么办？

| 数据量 | 推荐做法 |
|-------|---------|
| <1MB | RAG（检索增强），不训练 |
| 1-10MB | LoRA微调 |
| 10-100MB | LoRA或全参数微调 |
| >100MB | 全参数微调 |

### 9.4 版本迭代是什么？

模型更新 = 更好的权重 + 可能的架构改进 + 更多/更好的数据 + 更好的对齐

---

## 附录：常用术语速查表

| 术语          | 解释                         |
| ----------- | -------------------------- |
| LLM         | Large Language Model，大语言模型 |
| Transformer | 一种神经网络架构，LLM的基础            |
| Token       | 模型处理的最小单位（词或子词）            |
| Tokenizer   | 分词器，把文本转成token             |
| Embedding   | 词嵌入，把token转成向量             |
| Attention   | 注意力机制，让模型关注重要信息            |
| FFN         | 前馈网络，独立处理每个位置              |
| RoPE        | 旋转位置编码                     |
| MoE         | 混合专家模型                     |
| 预训练         | 用大量数据学习通用知识                |
| SFT         | 监督微调，学习对话格式                |
| LoRA        | 低秩适应，高效微调方法                |
| RLHF        | 人类反馈强化学习                   |
| DPO         | 直接偏好优化                     |
| 对齐          | 让模型行为符合人类期望                |
| 损失函数        | 衡量预测和答案差距的函数               |
| 梯度          | 参数调整的方向和大小                 |
| 反向传播        | 计算所有参数梯度的算法                |
| 优化器         | 决定如何更新参数的算法                |
| Batch Size  | 一次训练用多少条数据                 |
| Epoch       | 数据集完整遍历一次                  |
| 过拟合         | 模型记住数据而非学规律                |
| 欠拟合         | 模型没有学够                     |

---

## 学习资源推荐

1. **MiniMind 项目**：https://github.com/jingyaogong/minimind
   - 完整的LLM训练流程，代码简洁，适合入门
   
2. **PyTorch 官方教程**：https://pytorch.org/tutorials/
   
3. **Hugging Face 课程**：https://huggingface.co/learn

---

> 📝 **学习建议**：
> 1. 先理解概念，再看代码
> 2. 从小模型（MiniMind）开始实践
> 3. 动手跑一遍训练流程，印象更深
> 4. 遇到不懂的术语，回来查这份文档

---

*文档整理于 2026年1月*
*基于 MiniMind 项目学习笔记*
